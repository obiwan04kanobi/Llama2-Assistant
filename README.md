# Llama2-Assistant

## Description:
This repository contains code for interfacing with Meta's Llama2 model, a large language model (LLM) with 7 billion parameters. The code allows users to interact with the Llama2 model through a simple graphical user interface (GUI) implemented in Python. Users can input text queries, and the Llama2 model generates responses based on its training data.

## Features:
- Graphical User Interface (GUI) for interacting with the Llama2 model.
- Ability to input text queries and receive responses from the Llama2 model.
- Utilizes Meta's Llama2 model with 7 billion parameters for generating responses.

## Requirements:
- Python 3
- tkinter (for GUI implementation)
- Llama2 model from Meta (installed locally in system)

## Usage:
1. Clone the repository to your local machine:
   ```
   git clone https://github.com/username/Llama2-7B-Model.git
   ```

2. Install [Ollama](https://ollama.com/) Desktop application for your respective Operating System.

3. Extract the zip file and run the application (This will automatically set the "ollama" command in your OS's PATH).

4. Run the application:
   ```
   python llama2.py
   ```

5. Use the GUI interface to input text queries and receive responses from the Llama2 model.

## Additional Information:
- The Llama2 model used in this project is developed by Meta and contains 7 billion parameters.
- For more information about Meta's Llama2 model, refer to their [official documentation](https://llama.meta.com/llama2/).
- Contributions to this repository are welcome. Feel free to submit pull requests or open issues for any suggestions or improvements.

### License:
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

### Acknowledgements:
We would like to thank [Meta](https://about.meta.com/) for providing access to the Llama2 model and enabling us to develop this project.

-----------------------------------------------------------------------------------------------------------------
